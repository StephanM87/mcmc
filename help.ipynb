{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model fitting by sampling\n",
    "\n",
    "Hallo, ich versuche immer noch die theoretischen Grundlagen hinter der bayesian statistics und den Sampling Methoden zu finden. Berechnen kann ich das mittlerweile, nur die Theorie macht mir noch zu schaffen. Nach weiterem gesuche bin ich im Moment auf den folgenden Workflow gestossen:\n",
    "\n",
    "<img src=\"./assets/MCMCschemaneupng.png\" width=800>\n",
    "\n",
    "- **Schritt 1 auswählen des Modells.**\n",
    "\n",
    "in diesem fall ist das Modell die MM-kinetik: v =  $\\frac{vmax*z}{km+z} + \\sigma $\n",
    "\n",
    "mit z = Substratkonzentration <br>\n",
    "vmax = maximalgeschwindigkeit <br>\n",
    "km = MM-konstante <br>\n",
    "$\\sigma$ = Standardabweichung\n",
    "\n",
    "\n",
    "- **Schritt 2 Festlegen der Prior.**\n",
    "\n",
    "Hier wählt man nun Verteilungsfunktionen der Konstanten welche man mit dem Modell bestimmen will (in dem fall km, vamx und $\\sigma$). Jede Verteilung (falls normalverteilt) wird beschreiben durch einen Mittelwert µ und eine Standardabweichung $\\sigma$. Daraus ergeben sich dann 3 Verteilungen.\n",
    "\n",
    "**Schritt 3 Starten**\n",
    "\n",
    "Nun wird zufällig bzw. nach dem für was sich MCMC so entscheided, samples gezogen, dabei wird jeweils aus den 3 Wahrscheinlichekeitsverteilungen ein Wert gezogen und damit dann mittels der Michaelis Menten gleichung **v** bestimmt. Daraus resultiert dann eine sehr große Menge an berechneten **v** Werten aus welchen dann wieder eine Wahrscheinlickeitsverteilung gebildet wird nächmlich **P(0)**\n",
    "\n",
    "<details> <summary> frage 1: Verteilungen </summary>\n",
    "### Hierzu eine Frage\n",
    "\n",
    "wir können ja eigentlich nur jeweils für jede unabhängige variable (substratkonzentration (z)) einen Wert (v) berechnen oder? Soll meinen, wenn wir am Ende alle Samples gezogen haben müssten wir ja theoretisch für jede einzelne (Substratkonzentration) denn wir haben ja als Daten auch nur die einzelnen v Werte (bzw. Verteilungen) die wir vergleichen können:\n",
    "\n",
    "\n",
    "| Substratkonzentrationen | v Werte nach sampling |\n",
    "| ----------------------- | --------------------- |\n",
    "| x1                      | \\[v1-v1000\\]          |\n",
    "| x2                      | \\[v1-v1000\\]          |\n",
    "| x3                      | \\[v1-v1000\\]          |\n",
    "| x4                      | \\[v1-v1000\\]          |\n",
    "| x5                      | \\[v1-v1000\\]          |\n",
    "| x6                      | \\[v1-v1000\\]          |\n",
    "\n",
    "Das bedeuted ja auch, dass wir am ende für jedes v basierend auf den einzelenen Substratkonzentrationen (z) eine eigene Verteilungsfunktion bekommen, die wir dann mit den gemessene v-werten vergleichen können oder?!\n",
    "\n",
    "</details>\n",
    "\n",
    "**Schritt 4 Likelihood berechnen**\n",
    "\n",
    "Jetzt müssten wir theoretisch schon **P(0)** haben, um die Likelihood **P(v(gemessen) | 0)** zu bekommen, müssen wir ausrechnen, wie \"likely\" es ist, dass der gemessene Wert y (theoretisch ja auch eine verteilung) in **P(0)** vorkommt. Wie man das genau berechnen kann, habe ich auch noch nicht rausgefunden. Auf jeden fall multipliziert man dann **P(0)** mit **P(v(gemessen) | 0)** und bekommt eine neue verteilung nämlich die **Posterior** verteilung. \n",
    "\n",
    "Stimmt das so in etwa?"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
